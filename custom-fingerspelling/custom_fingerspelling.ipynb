{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle ASL Alphabet",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDwJO9lsbuTv",
        "colab_type": "text"
      },
      "source": [
        "The data for this notebook comes from our propriety fingerspelling image collection, which per our privacy statement _**should not**_ be seen by anyone but those directly working on this project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vhw70_FbDcp",
        "colab_type": "code",
        "outputId": "c8db634f-a04c-470e-e856-f7ec56ddb95b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "\"\"\"\n",
        "  1. Mount Google Drive (no need to check if already mounted, it does that for you)\n",
        "  2. \n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8KaspYaCf8k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf \"/content/fingerspelling\"\n",
        "!unzip \"/content/gdrive/My Drive/CS474 Final Project/CustomFingerspelling/360.zip\" > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAeEDSw1DsSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_dir = \"/content/fingerspelling\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak1Cqg7cP-kF",
        "colab_type": "code",
        "outputId": "339171a0-c013-4ae6-c28c-730ad626fb2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torchvision\n",
        "import os\n",
        "import gzip\n",
        "import tarfile\n",
        "import gc\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "assert torch.cuda.is_available(), \"You need to request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.3.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb5vda7aQSwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = torchvision.datasets.ImageFolder(\n",
        "          root_dir,\n",
        "          transform = transforms.Compose(\n",
        "              [\n",
        "               transforms.RandomGrayscale(0.4),\n",
        "               transforms.Resize(360), # Make it so we know where we're looking at least\n",
        "               transforms.RandomResizedCrop(224, (0.5, 1)),\n",
        "               transforms.RandomHorizontalFlip(),\n",
        "               transforms.RandomChoice([\n",
        "                 transforms.RandomPerspective(distortion_scale=0.2, p=0.75),\n",
        "                 transforms.RandomPerspective(distortion_scale=0.4, p=0.75),\n",
        "                 transforms.RandomPerspective(distortion_scale=0.6, p=0.75)]\n",
        "               ),\n",
        "               transforms.ToTensor(),\n",
        "               transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "               ]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6SgLCfRGwwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIkN49dZD_hP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 15\n",
        "validation_split = 0.08 # Gives roughly 26 in validation\n",
        "shuffle_dataset = True\n",
        "random_seed = 2019\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset:\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, \n",
        "                                           sampler=train_sampler)\n",
        "validation_loader = DataLoader(dataset, batch_size=batch_size,\n",
        "                                                sampler=valid_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vB7v78BHWiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x, y in train_loader:\n",
        "  for i, j in zip(x, y.tolist()):\n",
        "    print(dataset.classes[j])\n",
        "    imshow(i)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwJtylU7NSpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[dataset.classes[c] for imgs, batch in validation_loader for c in batch ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi4kQXjELNPK",
        "colab_type": "code",
        "outputId": "0c273d98-5734-4ae2-d51a-fa171d7a2e17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(\"Number in the train sampler: {}\".format(len(train_indices)))\n",
        "print(\"Number in the validate sampler: {}\".format(len(val_indices)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number in the train sampler: 332\n",
            "Number in the validate sampler: 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOurZtneWHxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize Model\n",
        "model = torchvision.models.resnet152(pretrained=True)\n",
        "num_f = model.fc.in_features\n",
        "model.fc = nn.Linear(num_f, len(dataset.classes))\n",
        "\n",
        "model = model.cuda() #use GPU\n",
        "\n",
        "# Initialize Objective and Optimizer and other parameters\n",
        "objective = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG-MDzwWpi3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKvaGpQVRFfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is what was talked about in the video for memory management\n",
        "num_epochs = 200\n",
        "valid_frequency = 1\n",
        "\n",
        "saved_epoch = -1\n",
        "\n",
        "train_losses = []\n",
        "validation_losses = []\n",
        "train_acc = []\n",
        "valid_acc = []\n",
        "\n",
        "def scope():\n",
        "  model_directory = \"/content/gdrive/My Drive/CS474 Final Project/CustomFingerspelling/Models4\"\n",
        "  best_loss = float(\"inf\")\n",
        "\n",
        "  try:\n",
        "    #your code for calling dataset and dataloader\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    loop = tqdm(\n",
        "        total=(len(train_loader) * num_epochs) +\n",
        "          (len(validation_loader) * (num_epochs // valid_frequency))\n",
        "        , position = 0)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      sum_loss = 0\n",
        "      count_loss = 0\n",
        "      sum_acc = 0\n",
        "      count_acc = 0\n",
        "\n",
        "      for batch_i, (x, y_truth) in enumerate(train_loader):\n",
        "        x, y_truth = x.cuda(async=True), y_truth.cuda(async=True)\n",
        "        optimizer.zero_grad()\n",
        "        y_hat = model(x)\n",
        "        y_long = y_truth.long()\n",
        "\n",
        "        # print(\"\\n\\n-----------\\ny_hat: {}, y_long: {}\\n-----------\\n\\n\".format(y_hat.size(), y_long.size()))\n",
        "        loss = objective(y_hat, y_long)\n",
        "        sum_loss += loss.item()\n",
        "        count_loss += 1\n",
        "\n",
        "        accuracy = 1- (torch.nonzero(torch.argmax(y_hat, 1) - y_truth).size(0) / len(y_truth))\n",
        "        sum_acc += accuracy\n",
        "        count_acc += 1\n",
        "\n",
        "        loop.set_description(\"epoch:{}, loss:{:.4f}, accuracy:{:.4f}\".format(epoch, loss.item(), accuracy))\n",
        "        loop.update(1)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Save model out if it's the new lowest loss.\n",
        "        if loss.item() < best_loss:\n",
        "          best_loss = loss.item()\n",
        "          state = {\n",
        "              'epoch': epoch,\n",
        "              'batch_i': batch_i,\n",
        "              'state': model.state_dict(),\n",
        "              'optim': optimizer.state_dict(),\n",
        "              'train_losses': train_losses,\n",
        "              'train_acc': train_acc,\n",
        "              'valid_losses': validation_losses,\n",
        "              'valid_acc': valid_acc,\n",
        "              'current_loss': loss.item()\n",
        "          }\n",
        "          model_file = os.path.join(model_directory, \"resnet152.mod\")\n",
        "          torch.save(state, model_file)\n",
        "\n",
        "      epoch_loss = sum_loss / count_loss\n",
        "      train_losses.append( (epoch, epoch_loss) )\n",
        "      epoch_acc = sum_acc / count_acc\n",
        "      train_acc.append( ( epoch, epoch_acc ) )\n",
        "      \n",
        "      if epoch % valid_frequency == 0:\n",
        "        sum_loss = 0\n",
        "        count_loss = 0\n",
        "        sum_acc = 0\n",
        "        count_acc = 0\n",
        "        with torch.no_grad():\n",
        "          for x, y_truth in validation_loader:\n",
        "            x, y_truth = x.cuda(async=True), y_truth.cuda(async=True)\n",
        "            y_hat = model(x)\n",
        "            loss = objective(y_hat, y_truth.long())\n",
        "            sum_loss += loss.item()\n",
        "            count_loss += 1       \n",
        "            accuracy = 1- (torch.nonzero(torch.argmax(y_hat, 1) - y_truth).size(0) / len(y_truth))\n",
        "            sum_acc += accuracy\n",
        "            count_acc += 1\n",
        "          \n",
        "          valid_acc.append((epoch, sum_acc / count_acc))\n",
        "          validation_losses.append((epoch, sum_loss / count_loss))\n",
        "      # Plot stuff.\n",
        "      # plt.plot(*zip(*train_losses), label=\"Training\")\n",
        "      # plt.plot(*zip(*validation_losses), label=\"Validation\")\n",
        "      # plt.draw() \n",
        "      # plt.pause(0.01)\n",
        "  except:\n",
        "    __ITB__()\n",
        "    raise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrPdgy_QtIFU",
        "colab_type": "code",
        "outputId": "613b96da-e139-4b6e-e1bb-dd2a1740a0b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "scope()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:135, loss:0.1441, accuracy:1.0000:  62%|██████▏   | 3105/5000 [50:20<21:51,  1.44it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X4xaP2EIFLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_losses)\n",
        "print(validation_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMeJFfEJWW6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title(\"Losses\")\n",
        "plt.plot(*zip(*train_losses), label=\"Training\")\n",
        "plt.plot(*zip(*validation_losses), label=\"Validation\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(*zip(*train_acc), label=\"Training\")\n",
        "plt.plot(*zip(*valid_acc), label=\"Validation\")\n",
        "plt.title(\"Training accuracies\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_76-Gznx55J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save that model out.\n",
        "torch.save(model.state_dict(), \"/content/gdrive/My Drive/CS474 Final Project/CustomFingerspelling/Models4/resnet152_end200.mod\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WGAvb0e4bRM",
        "colab_type": "text"
      },
      "source": [
        "# Validate Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWCHOL2i2fuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  1. Mount Google Drive (no need to check if already mounted, it does that for you)\n",
        "  2. \n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "root_dir = \"/content/gdrive/My Drive/models/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOUDNWPRVGu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file = \"/content/gdrive/My Drive/CS474 Final Project/Kaggle ASL Alphabet/loss_0.0304_epoch_4.mod\"\n",
        "loaded = torch.load(model_file)\n",
        "# print(loaded)\n",
        "model.load_state_dict(loaded)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbyILXQ4qAzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file = \"/content/gdrive/My Drive/CS474 Final Project/Kaggle ASL Alphabet/loss_0.0304_epoch_4.mod\"\n",
        "\n",
        "model = ConvNetwork(3, len(dataset.dataset_folder.classes), dimensions=128).cuda()\n",
        "model.load_state_dict(torch.load(model_file))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDh-TxqKrp1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cd \"/content/gdrive/My Drive/CS474 Final Project/Kaggle ASL Alphabet/\" && unzip Photos.zip\n",
        "!#mkdir \"/content/gdrive/My Drive/CS474 Final Project/Kaggle ASL Alphabet/Michelle\"\n",
        "#!mkdir \"/content/gdrive/My Drive/CS474 Final Project/Kaggle ASL Alphabet/Michelle/name\"\n",
        "\n",
        "!ls \"/content/gdrive/My Drive/CS474 Final Project/Kaggle ASL Alphabet/Michelle/name\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTatz_AWss_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# michelle_set = ASLDataset(\"/content/gdrive/My Drive/CS474 Final Project/Kaggle ASL Alphabet\", \"Michelle\", size=224)\n",
        "michelle_set = torchvision.datasets.ImageFolder(\n",
        "          \"/content/gdrive/My Drive/CS474 Final Project/Kaggle ASL Alphabet/Michelle\",\n",
        "          transform = transforms.Compose(\n",
        "              [\n",
        "               transforms.Resize(224),\n",
        "               transforms.CenterCrop(224), # Make it so we know where we're looking at least\n",
        "              #  transforms.RandomResizedCrop(224, (0.8, 1)),\n",
        "               transforms.ToTensor(),\n",
        "               transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "               ]))\n",
        "\n",
        "michelle_loader = DataLoader(michelle_set, batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h33lcSKs-V2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(michelle_set))\n",
        "print(len(michelle_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-kj-xYVw47K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "michelle_set.classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssLPZw_BtBP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batches = [model(i.cuda()) for i, j in michelle_loader]\n",
        "\"\".join([dataset.classes[torch.argmax(item)] for batch in batches for item in batch])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_2ePX5sAuIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum = 0\n",
        "for i, j in michelle_loader:\n",
        "  sum += 1\n",
        "  res = model(i.cuda())\n",
        "  chosen = torch.argmax(res, dim=1)\n",
        "  print(chosen)\n",
        "  actual = [dataset.classes[a] for a in j.tolist()]\n",
        "  solved = [dataset.classes[a] for a in chosen.tolist()]\n",
        "  for c, v in enumerate(zip(actual, solved)):\n",
        "    a, s = v\n",
        "    print(\"Actual: {} Guess: {}\".format(a, s))\n",
        "    try:\n",
        "      imshow(i[c])\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  if sum > 0:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drUvyXDJ5FGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum = 0\n",
        "for i, j in validation_loader:\n",
        "  sum += 1\n",
        "  res = model(i.cuda())\n",
        "  chosen = torch.argmax(res, dim=1)\n",
        "  print(chosen)\n",
        "  actual = [dataset.dataset_folder.classes[a] for a in j.tolist()]\n",
        "  solved = [dataset.dataset_folder.classes[a] for a in chosen.tolist()]\n",
        "  for c, v in enumerate(zip(actual, solved)):\n",
        "    a, s = v\n",
        "    print(\"Actual: {} Guess: {}\".format(a, s))\n",
        "    try:\n",
        "      imshow(i[c])\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  if sum > 0:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0S28sLOxKBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils as vutils\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIiRthPsxsW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_imgs(x, new_fig=True):\n",
        "    grid = vutils.make_grid(x.detach().cpu(), nrow=8, normalize=True, pad_value=0.3)\n",
        "    grid = grid.transpose(0,2).transpose(0,1) # channels as last dimension\n",
        "    if new_fig:\n",
        "        plt.figure()\n",
        "    plt.imshow(grid.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmznQylmxTQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x, y in michelle_loader:\n",
        "  show_imgs(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gNj0-7ePcRF",
        "colab_type": "text"
      },
      "source": [
        "# SSH Access\n",
        "\n",
        "If ssh_connect is True, an ssh server will be set up on the hosting server. Ergo power."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmJosbn3c0i_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ssh_connect = False\n",
        "if ssh_connect:\n",
        "  import random, string, getpass\n",
        "\n",
        "  password = ''.join(random.choice(string.ascii_letters + string.digits) for i in range(20))\n",
        "  alias = ''.join(random.choice(string.ascii_letters + string.digits) for i in range(8))\n",
        "  ! echo root:$password | chpasswd\n",
        "\n",
        "  ! apt-get install -qq -o=Dpkg::Use-Pty=0 openssh-server pwgen > /dev/null\n",
        "  ! mkdir -p /var/run/sshd\n",
        "  ! echo \"PermitRootLogin yes\" >> /etc/ssh/sshd_config && echo \"PasswordAuthentication yes\" >> /etc/ssh/sshd_config\n",
        "  ! echo \"LD_LIBRARY_PATH=/usr/lib64-nvidia\" >> /root/.bashrc && echo \"export LD_LIBRARY_PATH\" >> /root/.bashrc\n",
        "  get_ipython().system_raw('/usr/sbin/sshd -D &')\n",
        "\n",
        "  print('sshpass -p {} ssh -o \"StrictHostKeyChecking no\" -J serveo.net root@{}'.format(password, alias))\n",
        "  ! ssh -o \"StrictHostKeyChecking no\" -R $alias:22:localhost:22 serveo.net"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}