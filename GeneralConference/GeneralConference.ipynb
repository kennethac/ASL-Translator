{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GeneralConference.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te3Bjkwhe2Ue",
        "colab_type": "text"
      },
      "source": [
        "This notebook uses data scraped from the churchofjesuschrist.org website with ASL language general conference talks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uPsFv-ccwAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !curl -o gc.zip https://students.cs.byu.edu/~kac1995/2000.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOllGGoO0edW",
        "colab_type": "code",
        "outputId": "92f61d92-eebb-4924-a84c-ef9de1519bce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "\"\"\"\n",
        "  1. Mount Google Drive (no need to check if already mounted, it does that for you)\n",
        "  2. \n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPYkGq9k0nZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf \"/content/gc\"\n",
        "!unzip \"/content/gdrive/My Drive/CS474 Final Project/GC/2000.zip\" > /dev/null\n",
        "!mv \"/content/users/guest/k/kac1995/dev/CS474-General-Conference-Downloader/gc\" \"/content/gc\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN_UowwLoUzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# root directory has a structure like \"year/month/talk/[video|text]\"\n",
        "root_dir = \"/content/gc\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgRirH6MHIbf",
        "colab_type": "code",
        "outputId": "cc59ebf2-2e00-4484-f207-0301a709afb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm\n",
        "!sudo apt install libavdevice-dev libavfilter-dev > /dev/null # Required to get av to install\n",
        "!pip3 install av # Required for torchvision to work with videos.\n",
        "!pip install torchtext spacy\n",
        "!python -m spacy download en"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.3.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.4)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Collecting av\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/77/0be0fdaa3b7912c184705a4545ae6f1e9e47ab9e3834a3ef5caf2d7ca1e7/av-6.2.0.tar.gz (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 5.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: av\n",
            "  Building wheel for av (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for av: filename=av-6.2.0-cp36-cp36m-linux_x86_64.whl size=4975836 sha256=15980a243407cc65e5b17147e10130179b64c4ea34021e7173bb5fdec161a9ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/c1/b2/05e83d944cde5df317e4542082d67756ec4224c7885aee2d66\n",
            "Successfully built av\n",
            "Installing collected packages: av\n",
            "Successfully installed av-6.2.0\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.1.9)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.17.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.21.0)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.0)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.0.8)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.8)\n",
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p_UyQQ2HI4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms, utils, datasets\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import torchtext\n",
        "import spacy\n",
        "import gc\n",
        "import os\n",
        "import math\n",
        "import av\n",
        "import re\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "assert torch.cuda.is_available(), \"You need to request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNTxSKekHS-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !ls \"/content/gc/2000/04\"\n",
        "test_file = \"/content/gc/2000/04/are-you-still-here/frames.mp4\"\n",
        "vid, audio, meta = torchvision.io.video.read_video(test_file, pts_unit=\"sec\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj-zJMqyH8n1",
        "colab_type": "code",
        "outputId": "85fccc03-18b1-4319-a3e5-fc50ca6b1c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip3 install av # Required for torchvision to work with videos."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: av in /usr/local/lib/python3.6/dist-packages (6.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO0RMpJBKLAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_minutes = 1\n",
        "fps = 10\n",
        "sample_frames = sample_minutes * 60 * fps\n",
        "\n",
        "text_replacements = {\n",
        "    # end of paragraphs that may not have been done correctly\n",
        "    '\\.([^ ])': \". \\\\1\",\n",
        "    \"\\!([^ ])\": \"! \\\\1\",\n",
        "    \"\\?([^ ])\": \"? \\\\1\",\n",
        "    \"\\:([^ ])\": \": \\\\1\",\n",
        "    \n",
        "    # Some unicode chars that I know of\n",
        "    u\"\\u201c\": '\"',\n",
        "    u\"\\u201d\": '\"',\n",
        "    u\"\\u2018\": \"'\",\n",
        "    u\"\\u2019\": \"'\",\n",
        "    \"  +\": \" \"\n",
        "}\n",
        "\n",
        "class GeneralConferenceDataset(Dataset):\n",
        "  def __init__(self, root=root_dir, video_file=\"frames.mp4\", text_file=\"text.txt\", frames_per_item=sample_frames):\n",
        "    self.root_dir = root\n",
        "    self.video_file = video_file\n",
        "    self.text_file = text_file\n",
        "    self.frames_per_item = frames_per_item\n",
        "    self.years = self._discover_folders(root_dir)\n",
        "    self.months = self._discover_folders(self.years)\n",
        "    self.talks = self._discover_folders(self.months)\n",
        "    self.tokenizer = spacy.load('en').tokenizer\n",
        "  \n",
        "  def _discover_folders(self, parent):\n",
        "    if type(parent) != list: # we're gonna flatten lists, so this makes that easier\n",
        "      parent = [parent]\n",
        "    return [os.path.join(p, d.name) for p in parent for d in os.scandir(p) if d.is_dir()]\n",
        "\n",
        "  def _load_text(self, talk_dir, video_frames):\n",
        "    \"\"\"\n",
        "    Loads the text in the given talk as a list of word2vec vectors.\n",
        "\n",
        "    However, it does this by assuming that the temporal length is best measured by the number of word pieces, not the number of characters or english words\n",
        "    This is an assumption that we'll need to revisit in the future.\n",
        "    \"\"\"\n",
        "    with open(os.path.join(talk_dir, self.text_file), 'r') as f:\n",
        "      talk_text = f.read().lower()\n",
        "\n",
        "      # Because of the way that I downloaded the data, we need to separate sentences and replace crappy apostrophes.\n",
        "      for key in text_replacements:\n",
        "        talk_text = re.sub(key, text_replacements[key], talk_text)\n",
        "      \n",
        "      tokens = self.tokenizer(talk_text)\n",
        "      num_tokens = len(tokens)\n",
        "      desired_length = math.ceil((self.frames_per_item / video_frames) * num_tokens)\n",
        "      start_token = random.randint(0, num_tokens - desired_length)\n",
        "\n",
        "      token_sample = tokens[start_token:start_token + desired_length]\n",
        "      return token_sample\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    \"\"\"\n",
        "      Returns a random sample of the video at index, and the text we hope that it represents.\n",
        "    \"\"\"\n",
        "    # Load the video and get a samle of the frames. Video is of size [num_frames, h, w, c]\n",
        "    talk_dir = self.talks[index]\n",
        "    video, _, meta = torchvision.io.video.read_video(os.path.join(talk_dir, self.video_file), pts_unit=\"sec\")\n",
        "    num_frames = video.size(0)\n",
        "    length = self.frames_per_item\n",
        "    start_frame = random.randint( 0, num_frames - length )\n",
        "    frame_sample = video[start_frame:start_frame + length]\n",
        "\n",
        "    # Now get a chunk of text of hopefully comparable spot.\n",
        "    text_sample = self._load_text(talk_dir, num_frames)\n",
        "    return frame_sample, text_sample\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.talks)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6HE1Qu6Nrme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = GeneralConferenceDataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sG-gkCENt19",
        "colab_type": "code",
        "outputId": "ed1a389c-67b4-459a-ac59-02f96386f1f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        }
      },
      "source": [
        "# An example of a piece of text. F is the frames.\n",
        "f, t = dataset[0]\n",
        "print(t)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\\.([^ ])___. \\1\n",
            "\\!([^ ])___! \\1\n",
            "\\?([^ ])___? \\1\n",
            "\\:([^ ])___: \\1\n",
            "“___\"\n",
            "”___\"\n",
            "‘___'\n",
            "’___'\n",
            "  +___ \n",
            "Num tokens: 3283\n",
            "Desired length: 600 // 14330 = 138 \n",
            "Start token: 1664\n",
            "been permitted to come on the scene at this time when there is such a great flowering of knowledge. what a tragedy it is, what a bleak and terrible thing to witness a son or daughter on whom you counted so much walk the tortuous path that leads down to hell. on the other hand, what a glorious and beautiful thing it is to see the child of your dreams walk with head up, standing tall, unafraid, and with confidence, taking advantage of the tremendous opportunities that open around him or her. isaiah said, \"all thy children shall be taught of the lord; and great shall be the peace of thy children\" (isa. 54: 13). so lead your sons and\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ww24TWKNlCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GeneralConferenceModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GeneralConferenceModel, self).__init__()\n",
        "    self.net = nn.Transformer() # Parameters should be tweaked, probably\n",
        "\n",
        "  def forward(self, frames):\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_dSy1KMN7-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}