{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GeneralConference.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te3Bjkwhe2Ue",
        "colab_type": "text"
      },
      "source": [
        "This notebook uses data scraped from the churchofjesuschrist.org website with ASL language general conference talks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uPsFv-ccwAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !curl -o gc.zip https://students.cs.byu.edu/~kac1995/2000.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOllGGoO0edW",
        "colab_type": "code",
        "outputId": "b389e146-1a76-4024-968d-de5a108594c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "\"\"\"\n",
        "  1. Mount Google Drive (no need to check if already mounted, it does that for you)\n",
        "  2. \n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPYkGq9k0nZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf \"/content/gc\"\n",
        "!unzip \"/content/gdrive/My Drive/CS474 Final Project/GC/2000.zip\" > /dev/null\n",
        "!mv \"/content/users/guest/k/kac1995/dev/CS474-General-Conference-Downloader/gc\" \"/content/gc\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN_UowwLoUzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# root directory has a structure like \"year/month/talk/[video|text]\"\n",
        "root_dir = \"/content/gc\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgRirH6MHIbf",
        "colab_type": "code",
        "outputId": "c4c554a9-cefd-42ad-cdda-bed9557868b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm\n",
        "!sudo apt install libavdevice-dev libavfilter-dev > /dev/null # Required to get av to install\n",
        "!pip3 install av # Required for torchvision to work with videos.\n",
        "!pip install torchtext spacy\n",
        "!python -m spacy download en\n",
        "!pip3 install gensim"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Collecting av\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/77/0be0fdaa3b7912c184705a4545ae6f1e9e47ab9e3834a3ef5caf2d7ca1e7/av-6.2.0.tar.gz (2.0MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0MB 2.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: av\n",
            "  Building wheel for av (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for av: filename=av-6.2.0-cp36-cp36m-linux_x86_64.whl size=4975814 sha256=fbff3ba4eb86260541c02f58246563c079eb293bcdb4d1835affc2f7124b1ed0\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/c1/b2/05e83d944cde5df317e4542082d67756ec4224c7885aee2d66\n",
            "Successfully built av\n",
            "Installing collected packages: av\n",
            "Successfully installed av-6.2.0\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.1.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.17.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.28.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2019.11.28)\n",
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.9.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.17.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.10.36)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.36 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.13.36)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->smart-open>=1.2.1->gensim) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p_UyQQ2HI4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms, utils, datasets\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import torchtext\n",
        "import spacy\n",
        "import gc\n",
        "import os\n",
        "import math\n",
        "import av\n",
        "import re\n",
        "import gensim.downloader as gensim_api\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "assert torch.cuda.is_available(), \"You need to request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FkduX1Wv_eK",
        "colab_type": "code",
        "outputId": "f83549b4-ea1e-41bc-e45e-cfbc508d3286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "!pip install gputil\n",
        "import GPUtil as GPU\n",
        "\n",
        "def clean():\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "def check_gpu():\n",
        "  GPUs = GPU.getGPUs()\n",
        "  gpu = GPUs[0]\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "clean()\n",
        "check_gpu()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=620a0195288337f86b89c0987162200a941867f461bdc97fb83ffe6543b41e44\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "GPU RAM Free: 16270MB | Used: 10MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNvOPp1Jol5K",
        "colab_type": "code",
        "outputId": "9f96a605-a895-4872-ff66-5ad78d2c2681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "model_glove_wikipedia = gensim_api.load(\"glove-wiki-gigaword-100\")\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDfXDVZUplq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_length = len(model_glove_wikipedia[\"jesus\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO0RMpJBKLAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_minutes = 1\n",
        "fps = 10\n",
        "sample_frames = sample_minutes * 60 * fps\n",
        "\n",
        "text_replacements = {\n",
        "    # end of paragraphs that may not have been done correctly\n",
        "    '\\.([^ ])': \". \\\\1\",\n",
        "    \"\\!([^ ])\": \"! \\\\1\",\n",
        "    \"\\?([^ ])\": \"? \\\\1\",\n",
        "    \"\\:([^ ])\": \": \\\\1\",\n",
        "    \n",
        "    # Some unicode chars that I know of\n",
        "    u\"\\u201c\": '\"',\n",
        "    u\"\\u201d\": '\"',\n",
        "    u\"\\u2018\": \"'\",\n",
        "    u\"\\u2019\": \"'\",\n",
        "    \"  +\": \" \"\n",
        "}\n",
        "\n",
        "class GeneralConferenceDataset(Dataset):\n",
        "  def __init__(self, root=root_dir, video_file=\"frames.mp4\", text_file=\"text.txt\", frames_per_item=sample_frames):\n",
        "    self.root_dir = root\n",
        "    self.video_file = video_file\n",
        "    self.text_file = text_file\n",
        "    self.frames_per_item = frames_per_item\n",
        "    self.years = self._discover_folders(root_dir)\n",
        "    self.months = self._discover_folders(self.years)\n",
        "    self.talks = self._discover_folders(self.months)\n",
        "    self.tokenizer = spacy.load('en').tokenizer\n",
        "    self.transforms = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Lambda(lambda img: img.transpose(0, 2)),\n",
        "        torchvision.transforms.ToPILImage(),\n",
        "        torchvision.transforms.Resize(224),                \n",
        "        torchvision.transforms.CenterCrop(224),\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "  def _discover_folders(self, parent):\n",
        "    if type(parent) != list: # we're gonna flatten lists, so this makes that easier\n",
        "      parent = [parent]\n",
        "    return [os.path.join(p, d.name) for p in parent for d in os.scandir(p) if d.is_dir()]\n",
        "\n",
        "  def _load_text(self, talk_dir, video_frames):\n",
        "    \"\"\"\n",
        "    Loads the text in the given talk as a list of word2vec vectors.\n",
        "\n",
        "    However, it does this by assuming that the temporal length is best measured by the number of word pieces, not the number of characters or english words\n",
        "    This is an assumption that we'll need to revisit in the future.\n",
        "    \"\"\"\n",
        "    with open(os.path.join(talk_dir, self.text_file), 'r') as f:\n",
        "      talk_text = f.read().lower()\n",
        "\n",
        "      # Because of the way that I downloaded the data, we need to separate sentences and replace crappy apostrophes.\n",
        "      for key in text_replacements:\n",
        "        talk_text = re.sub(key, text_replacements[key], talk_text)\n",
        "      \n",
        "      tokens = self.tokenizer(talk_text)\n",
        "      num_tokens = len(tokens)\n",
        "      desired_length = math.ceil((self.frames_per_item / video_frames) * num_tokens)\n",
        "      start_token = random.randint(0, num_tokens - desired_length)\n",
        "\n",
        "      token_sample = tokens[start_token:start_token + desired_length]\n",
        "      return token_sample\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    \"\"\"\n",
        "      Returns a random sample of the video at index, and the text we hope that it represents.\n",
        "    \"\"\"\n",
        "    # Load the video and get a sample of the frames. Video is of size [num_frames, h, w, c]\n",
        "    talk_dir = self.talks[index]\n",
        "    video, _, meta = torchvision.io.video.read_video(os.path.join(talk_dir, self.video_file), pts_unit=\"sec\")\n",
        "    num_frames = video.size(0)\n",
        "    length = self.frames_per_item\n",
        "    start_frame = random.randint( 0, num_frames - length )\n",
        "    frame_sample = video[start_frame:start_frame + length]\n",
        "\n",
        "    # Apply some transforms to the frames (but the same transform for every frame in video)\n",
        "    frame_sample = torch.stack([self.transforms(i) for i in frame_sample])\n",
        "\n",
        "    # Now get a chunk of text of hopefully comparable spot.\n",
        "    text_sample = self._load_text(talk_dir, num_frames)\n",
        "    return frame_sample, text_sample\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.talks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6HE1Qu6Nrme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = GeneralConferenceDataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1AafyhsgGcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((2, 1, 0))\n",
        "    # mean = np.array([0.485, 0.456, 0.406])\n",
        "    # std = np.array([0.229, 0.224, 0.225])\n",
        "    # inp = std * inp + mean\n",
        "    # inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ww24TWKNlCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GeneralConferenceModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GeneralConferenceModel, self).__init__()\n",
        "    self.feature_extracter = torchvision.models.resnet50(pretrained=True)\n",
        "    for param in self.feature_extracter.parameters():\n",
        "      param.requires_grad = False\n",
        "    num_f = self.feature_extracter.fc.in_features\n",
        "    self.feature_extracter.fc = nn.Linear(num_f, 100)\n",
        "\n",
        "    self.net = nn.LSTM(input_size=100, hidden_size=100, num_layers=2, batch_first=True) # Parameters should be tweaked, probably\n",
        "\n",
        "  def forward(self, frames, hidden=None, num_chunks=20):\n",
        "    # Extract features\n",
        "    print('Entering foward method:',frames.size())\n",
        "    chunk_size = len(frames) // num_chunks\n",
        "    features = []\n",
        "    for i in range(num_chunks):\n",
        "      frame_piece = frames[i*chunk_size:(i+1)*chunk_size]\n",
        "      frame_piece = frame_piece.cuda()\n",
        "      f = self.feature_extracter(frame_piece)\n",
        "      features.append(f)\n",
        "      frame_piece = frame_piece.cpu()\n",
        "    frame_features = torch.cat(features, dim=0)\n",
        "    print('Features have been extracted:',frame_features.size())\n",
        "    # LSTM expects them with shape (batch, time_sequence, input_size)\n",
        "    frame_features = frame_features.unsqueeze(0)\n",
        "    embeddings, hidden = self.net(frame_features, hidden)\n",
        "    print('Embeddings generated:',embeddings.size())\n",
        "    return embeddings, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl3ELFRic6SK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate_emb(embeddings):\n",
        "  results = []\n",
        "  for e in embeddings.numpy():\n",
        "    top_choices = model_glove_wikipedia.similar_by_vector(e)\n",
        "    words, weights = zip(*top_choices)\n",
        "    weights = np.asarray(weights)\n",
        "    weights /= np.sum(weights)\n",
        "    word = np.random.choice(words, p=weights)\n",
        "    results.append(word)\n",
        "  return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_dSy1KMN7-2",
        "colab_type": "code",
        "outputId": "15661ff8-fc19-4062-f4f4-1eaeeb01ccd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# clean() and check_gpu() are located at the bottom of the notebook\n",
        "check_gpu()\n",
        "clean()\n",
        "model = GeneralConferenceModel()\n",
        "model = model.cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "check_gpu()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU RAM Free: 16270MB | Used: 10MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 302MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GPU RAM Free: 15439MB | Used: 841MB | Util   5% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQc0XggNVTUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmbeddingLookupModule(nn.Module):\n",
        "  def forward(self, l):\n",
        "    l = l.int().numpy()\n",
        "    # print(type(l))\n",
        "    # print(\"l size: {}\".format(l.shape))\n",
        "    res = torch.tensor(embeddings[l]).float().transpose(0,1)\n",
        "    # print(\"Looked up size: {}\".format(res.size()))\n",
        "    return res.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXcgjeC8VM8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "fat_grader = nn.Sequential(\n",
        "    EmbeddingLookupModule(),\n",
        "    nn.LSTM(input_size=100, hidden_size=200)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQc2I6amuySc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load siamese lstm\n",
        "grader = nn.LSTM(input_size=100, hidden_size=200)\n",
        "# grader = grader.load()\n",
        "grader = grader.cuda().eval()\n",
        "objective = nn.MSELoss()\n",
        "def compute_manhattan(h1, h2):\n",
        "  return torch.exp(-torch.sum(torch.abs(h1 - h2), axis=2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e08ZuemxTfA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Because in training the MaLSTM I unthinkingly saved out the entire sequential\n",
        "# model I have to recreate it in fat_grader, restore the params we want, \n",
        "# then pull out the LSTM portion of the fat_grader.\n",
        "grader_model_file = \"/content/gdrive/My Drive/CS474 Final Project/MaLSTM/e49_l0.17679482698440552.mod\"\n",
        "mk, uk = fat_grader.load_state_dict(torch.load(grader_model_file))\n",
        "grader = [ i for i in fat_grader.modules() ][2]\n",
        "assert len(mk) == len(uk) and len(uk) == 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQYVYSZAaT7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(num_epochs):\n",
        "  try:\n",
        "    for e in range(num_epochs):\n",
        "      for i in range(len(dataset)):\n",
        "        check_gpu()\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        vid, text = dataset[i]\n",
        "        check_gpu()\n",
        "        text_hat = []\n",
        "        hidden = None\n",
        "        for j in range(6):\n",
        "          check_gpu()\n",
        "          t, hidden = model(vid[j*100:(j+1)*100], hidden)\n",
        "          text_hat.append(t.squeeze(0))\n",
        "        text_hat = torch.cat(text_hat, dim=0)\n",
        "        check_gpu()\n",
        "        print('Full group processed:',text_hat.size())\n",
        "        if i % 5 == 0:\n",
        "          to_translate = text_hat.clone().detach().cpu().squeeze(0).squeeze(0)\n",
        "          results = translate_emb(to_translate)\n",
        "          print(results)\n",
        "\n",
        "        _, (h_hat, _) = grader(text_hat)\n",
        "        _, (h_text, _) = grader(text)\n",
        "        dist = compute_manhattan(h_hat, h_text).squeeze(0)\n",
        "        all_are_similar = torch.ones(dist.shape).cuda()\n",
        "        loss(dist, all_are_similar)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        break\n",
        "      break\n",
        "  except Exception:\n",
        "    __ITB__()\n",
        "    raise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2Xr7n0YrsVH",
        "colab_type": "code",
        "outputId": "b6f5f4e0-27d8-4a0a-9a7d-72f383fc1d61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train(4)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU RAM Free: 15435MB | Used: 845MB | Util   5% | Total 16280MB\n",
            "GPU RAM Free: 15439MB | Used: 841MB | Util   5% | Total 16280MB\n",
            "GPU RAM Free: 15439MB | Used: 841MB | Util   5% | Total 16280MB\n",
            "Entering foward method: torch.Size([100, 3, 224, 224])\n",
            "Features have been extracted: torch.Size([100, 100])\n",
            "Embeddings generated: torch.Size([1, 100, 100])\n",
            "GPU RAM Free: 15363MB | Used: 917MB | Util   6% | Total 16280MB\n",
            "Entering foward method: torch.Size([100, 3, 224, 224])\n",
            "Features have been extracted: torch.Size([100, 100])\n",
            "Embeddings generated: torch.Size([1, 100, 100])\n",
            "GPU RAM Free: 15361MB | Used: 919MB | Util   6% | Total 16280MB\n",
            "Entering foward method: torch.Size([100, 3, 224, 224])\n",
            "Features have been extracted: torch.Size([100, 100])\n",
            "Embeddings generated: torch.Size([1, 100, 100])\n",
            "GPU RAM Free: 15359MB | Used: 921MB | Util   6% | Total 16280MB\n",
            "Entering foward method: torch.Size([100, 3, 224, 224])\n",
            "Features have been extracted: torch.Size([100, 100])\n",
            "Embeddings generated: torch.Size([1, 100, 100])\n",
            "GPU RAM Free: 15359MB | Used: 921MB | Util   6% | Total 16280MB\n",
            "Entering foward method: torch.Size([100, 3, 224, 224])\n",
            "Features have been extracted: torch.Size([100, 100])\n",
            "Embeddings generated: torch.Size([1, 100, 100])\n",
            "GPU RAM Free: 15357MB | Used: 923MB | Util   6% | Total 16280MB\n",
            "Entering foward method: torch.Size([100, 3, 224, 224])\n",
            "Features have been extracted: torch.Size([100, 100])\n",
            "Embeddings generated: torch.Size([1, 100, 100])\n",
            "GPU RAM Free: 15355MB | Used: 925MB | Util   6% | Total 16280MB\n",
            "Full group processed: torch.Size([600, 100])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['bebo', 'laogai', 'http://www.billboard.com', 'cubicles', 'copernicus', 'coxnc.com', 'cubicles', 'copernicus', 'http://www.billboard.com', 'http://www.billboard.com', 'descartes', 'cubicle', 'copernicus', 'vandore', 'laogai', 'descartes', 'descartes', 'alevine', 'bebo', 'copernicus', 'cseabrook', 'kevinthompson', 'cubicles', 'descartes', 'copernicus', 'kevinthompson', 'copernicus', 'copernicus', 'coxnc.com', 'http://www.billboard.com', 'laogai', 'alevine', 'cubicles', 'alevine', 'coxnc.com', 'alevine', 'cubicles', 'bbn', 'http://www.billboard.com', 'coxnc.com', 'copernicus', 'kevinthompson', 'laogai', 'vandore', 'alevine', 'cubicle', 'dimples', 'bebo', 'http://www.billboard.com', 'kevinthompson', 'http://www.billboard.com', 'descartes', 'cubicles', 'http://www.billboard.com', 'kevinthompson', 'alevine', 'cubicles', 'http://www.billboard.com', 'alevine', 'laogai', 'copernicus', 'descartes', 'bbn', 'copernicus', 'cubicles', 'cubicles', 'descartes', 'descartes', 'descartes', 'http://www.billboard.com', 'coxnc.com', 'http://www.billboard.com', 'alevine', 'bebo', 'descartes', 'bebo', 'laogai', 'bebo', 'laogai', 'kevinthompson', 'alevine', 'cubicles', 'http://www.billboard.com', 'alevine', 'descartes', 'cubicle', 'cubicles', 'cubicles', 'bebo', 'alevine', 'laogai', 'vandore', 'alevine', 'http://www.billboard.com', 'bbn', 'alevine', 'alevine', 'http://www.billboard.com', 'cubicles', 'descartes', 'coxnc.com', 'alevine', 'cubicles', 'http://www.billboard.com', 'cubicles', 'copernicus', 'bebo', 'copernicus', 'vandore', 'alevine', 'copernicus', 'cubicles', 'laogai', 'alevine', 'http://www.billboard.com', 'copernicus', 'laogai', 'bebo', 'laogai', 'alevine', 'cubicles', 'laogai', 'http://www.billboard.com', 'kevinthompson', 'copernicus', 'cubicles', 'alevine', 'copernicus', 'http://www.billboard.com', 'bbn', 'http://www.billboard.com', 'bbn', 'alevine', 'laogai', 'cubicles', 'descartes', 'dimples', 'alevine', 'copernicus', 'kevinthompson', 'http://www.billboard.com', 'bebo', 'copernicus', 'descartes', 'laogai', 'vandore', 'laogai', 'coxnc.com', 'vandore', 'laogai', 'coxnc.com', 'coxnc.com', 'bbn', 'bebo', 'laogai', 'descartes', 'http://www.billboard.com', 'alevine', 'cubicles', 'descartes', 'cubicles', 'http://www.billboard.com', 'descartes', 'vandore', 'laogai', 'laogai', 'http://www.billboard.com', 'copernicus', 'cubicle', 'cubicles', 'descartes', 'alevine', 'cubicles', 'kevinthompson', 'alevine', 'cubicles', 'laogai', 'cubicle', 'descartes', 'kevinthompson', 'wisse', 'http://www.billboard.com', 'vandore', 'vandore', 'http://www.billboard.com', 'vandore', 'bebo', 'kevinthompson', 'descartes', 'cubicle', 'descartes', 'copernicus', 'copernicus', 'bebo', 'cubicles', 'bebo', 'laogai', 'bebo', 'http://www.billboard.com', 'copernicus', 'alevine', 'vandore', 'alevine', 'descartes', 'alevine', 'descartes', 'dimples', 'http://www.billboard.com', 'coxnc.com', 'copernicus', 'http://www.billboard.com', 'http://www.billboard.com', 'cubicle', 'descartes', 'http://www.billboard.com', 'laogai', 'http://www.billboard.com', 'bebo', 'laogai', 'copernicus', 'vandore', 'descartes', 'http://www.billboard.com', 'http://www.billboard.com', 'dimples', 'laogai', 'laogai', 'copernicus', 'http://www.billboard.com', 'coxnc.com', 'http://www.billboard.com', 'cseabrook', 'laogai', 'vandore', 'laogai', 'descartes', 'cubicle', 'vandore', 'laogai', 'coxnc.com', 'cubicles', 'alevine', 'copernicus', 'descartes', 'copernicus', 'coxnc.com', 'http://www.billboard.com', 'cubicle', 'descartes', 'http://www.billboard.com', 'coxnc.com', 'alevine', 'alevine', 'kevinthompson', 'descartes', 'laogai', 'vandore', 'bebo', 'coxnc.com', 'copernicus', 'bebo', 'cubicles', 'coxnc.com', 'bebo', 'cubicle', 'copernicus', 'descartes', 'copernicus', 'descartes', 'coxnc.com', 'http://www.billboard.com', 'descartes', 'http://www.billboard.com', 'copernicus', 'copernicus', 'cubicles', 'coxnc.com', 'coxnc.com', 'alevine', 'bebo', 'laogai', 'copernicus', 'laogai', 'copernicus', 'bebo', 'cubicle', 'coxnc.com', 'copernicus', 'coxnc.com', 'http://www.billboard.com', 'coxnc.com', 'laogai', 'coxnc.com', 'http://www.billboard.com', 'descartes', 'cubicle', 'descartes', 'kevinthompson', 'laogai', 'copernicus', 'bebo', 'laogai', 'bebo', 'coxnc.com', 'laogai', 'bebo', 'alevine', 'cubicles', 'copernicus', 'descartes', 'laogai', 'descartes', 'http://www.billboard.com', 'wisse', 'descartes', 'alevine', 'coxnc.com', 'alevine', 'bbn', 'kevinthompson', 'laogai', 'laogai', 'coxnc.com', 'laogai', 'copernicus', 'vandore', 'copernicus', 'bebo', 'cubicles', 'http://www.billboard.com', 'http://www.billboard.com', 'kevinthompson', 'http://www.billboard.com', 'coxnc.com', 'cubicle', 'http://www.billboard.com', 'bebo', 'vandore', 'laogai', 'bebo', 'bebo', 'http://www.billboard.com', 'coxnc.com', 'copernicus', 'alevine', 'cubicles', 'coxnc.com', 'copernicus', 'alevine', 'http://www.billboard.com', 'copernicus', 'descartes', 'laogai', 'bbn', 'copernicus', 'alevine', 'http://www.billboard.com', 'descartes', 'alevine', 'kevinthompson', 'descartes', 'cubicles', 'laogai', 'alevine', 'alevine', 'http://www.billboard.com', 'descartes', 'ephemeris', 'alevine', 'coxnc.com', 'copernicus', 'coxnc.com', 'kevinthompson', 'coxnc.com', 'http://www.billboard.com', 'laogai', 'cubicles', 'kevinthompson', 'alevine', 'descartes', 'coxnc.com', 'kevinthompson', 'cubicles', 'cubicles', 'descartes', 'descartes', 'cubicles', 'http://www.billboard.com', 'descartes', 'descartes', 'laogai', 'laogai', 'dimples', 'descartes', 'copernicus', 'bebo', 'kevinthompson', 'cseabrook', 'cubicles', 'coxnc.com', 'cubicles', 'bebo', 'coxnc.com', 'laogai', 'vandore', 'cubicles', 'copernicus', 'coxnc.com', 'descartes', 'bebo', 'laogai', 'laogai', 'kevinthompson', 'bebo', 'alevine', 'cubicles', 'coxnc.com', 'http://www.billboard.com', 'laogai', 'cubicle', 'dimples', 'descartes', 'coxnc.com', 'alevine', 'descartes', 'coxnc.com', 'http://www.billboard.com', 'kevinthompson', 'alevine', 'cubicles', 'cubicles', 'copernicus', 'descartes', 'descartes', 'http://www.billboard.com', 'descartes', 'cubicle', 'copernicus', 'alevine', 'laogai', 'cubicle', 'alevine', 'dimples', 'descartes', 'cubicle', 'cubicles', 'coxnc.com', 'copernicus', 'alevine', 'bebo', 'bbn', 'bebo', 'laogai', 'coxnc.com', 'http://www.billboard.com', 'coxnc.com', 'coxnc.com', 'copernicus', 'dimples', 'http://www.billboard.com', 'bebo', 'copernicus', 'kevinthompson', 'coxnc.com', 'bebo', 'http://www.billboard.com', 'cubicle', 'dimples', 'bbn', 'bebo', 'alevine', 'cubicle', 'copernicus', 'http://www.billboard.com', 'descartes', 'bebo', 'alevine', 'dimples', 'cubicles', 'bebo', 'descartes', 'coxnc.com', 'descartes', 'cubicles', 'coxnc.com', 'http://www.billboard.com', 'kevinthompson', 'copernicus', 'bebo', 'descartes', 'kevinthompson', 'coxnc.com', 'alevine', 'coxnc.com', 'laogai', 'coxnc.com', 'http://www.billboard.com', 'coxnc.com', 'copernicus', 'descartes', 'descartes', 'cubicles', 'laogai', 'kevinthompson', 'alevine', 'alevine', 'alevine', 'vandore', 'descartes', 'vandore', 'bebo', 'descartes', 'cubicle', 'http://www.billboard.com', 'cubicles', 'cubicles', 'kevinthompson', 'descartes', 'descartes', 'bebo', 'cubicles', 'bebo', 'http://www.billboard.com', 'kevinthompson', 'alevine', 'copernicus', 'descartes', 'vandore', 'laogai', 'http://www.billboard.com', 'bbn', 'laogai', 'kevinthompson', 'cubicles', 'coxnc.com', 'cubicles', 'vandore', 'cubicle', 'bebo', 'coxnc.com', 'descartes', 'alevine', 'copernicus', 'laogai', 'cubicles', 'alevine', 'cubicle', 'vandore', 'copernicus', 'http://www.billboard.com', 'cubicles', 'http://www.billboard.com', 'descartes', 'bbn', 'bebo', 'descartes', 'vandore', 'laogai', 'laogai', 'copernicus', 'alevine', 'alevine', 'laogai', 'kevinthompson', 'descartes', 'copernicus', 'coxnc.com', 'laogai', 'http://www.billboard.com', 'kevinthompson', 'bebo', 'cubicles', 'kevinthompson', 'http://www.billboard.com', 'http://www.billboard.com', 'descartes', 'http://www.billboard.com', 'alevine', 'copernicus', 'kevinthompson', 'alevine', 'copernicus', 'http://www.billboard.com', 'copernicus', 'laogai', 'copernicus', 'laogai', 'laogai', 'laogai', 'bebo', 'bebo', 'kevinthompson', 'kevinthompson', 'kevinthompson', 'http://www.billboard.com', 'kevinthompson', 'vandore', 'copernicus', 'laogai', 'alevine']\n",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self=LSTM(100, 200), *input=(tensor([[-0.0265,  0.0039, -0.0380,  ..., -0.007...],\n",
            "       device='cuda:0', grad_fn=<CatBackward>),), **kwargs={})\u001b[0m\n",
            "\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mresult\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself.forward\u001b[0m \u001b[0;34m= <bound method LSTM.forward of LSTM(100, 200)>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36minput\u001b[0m \u001b[0;34m= (tensor([[-0.0265,  0.0039, -0.0380,  ..., -0.0075, -0.0019, -0.0048],\n",
            "        [-0.0377,  0.0153, -0.0527,  ..., -0.0179, -0.0020, -0.0122],\n",
            "        [-0.0400,  0.0250, -0.0616,  ..., -0.0276,  0.0002, -0.0201],\n",
            "        ...,\n",
            "        [-0.0382,  0.0486, -0.0742,  ..., -0.0481, -0.0111, -0.0347],\n",
            "        [-0.0364,  0.0485, -0.0742,  ..., -0.0442, -0.0083, -0.0350],\n",
            "        [-0.0346,  0.0509, -0.0758,  ..., -0.0458, -0.0014, -0.0341]],\n",
            "       device='cuda:0', grad_fn=<CatBackward>),)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mkwargs\u001b[0m \u001b[0;34m= {}\u001b[0m\n",
            "\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self=LSTM(100, 200), input=tensor([[-0.0265,  0.0039, -0.0380,  ..., -0.007...],\n",
            "       device='cuda:0', grad_fn=<CatBackward>), hx=None)\u001b[0m\n",
            "\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mself.forward_tensor\u001b[0m \u001b[0;34m= <bound method LSTM.forward_tensor of LSTM(100, 200)>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36minput\u001b[0m \u001b[0;34m= tensor([[-0.0265,  0.0039, -0.0380,  ..., -0.0075, -0.0019, -0.0048],\n",
            "        [-0.0377,  0.0153, -0.0527,  ..., -0.0179, -0.0020, -0.0122],\n",
            "        [-0.0400,  0.0250, -0.0616,  ..., -0.0276,  0.0002, -0.0201],\n",
            "        ...,\n",
            "        [-0.0382,  0.0486, -0.0742,  ..., -0.0481, -0.0111, -0.0347],\n",
            "        [-0.0364,  0.0485, -0.0742,  ..., -0.0442, -0.0083, -0.0350],\n",
            "        [-0.0346,  0.0509, -0.0758,  ..., -0.0458, -0.0014, -0.0341]],\n",
            "       device='cuda:0', grad_fn=<CatBackward>)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mhx\u001b[0m \u001b[0;34m= None\u001b[0m\n",
            "\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self=LSTM(100, 200), input=tensor([[-0.0265,  0.0039, -0.0380,  ..., -0.007...],\n",
            "       device='cuda:0', grad_fn=<CatBackward>), hx=None)\u001b[0m\n",
            "\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36moutput\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mhidden\u001b[0m \u001b[0;34m= \u001b[0;36mundefined\u001b[0m\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mself.forward_impl\u001b[0m \u001b[0;34m= <bound method LSTM.forward_impl of LSTM(100, 200)>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36minput\u001b[0m \u001b[0;34m= tensor([[-0.0265,  0.0039, -0.0380,  ..., -0.0075, -0.0019, -0.0048],\n",
            "        [-0.0377,  0.0153, -0.0527,  ..., -0.0179, -0.0020, -0.0122],\n",
            "        [-0.0400,  0.0250, -0.0616,  ..., -0.0276,  0.0002, -0.0201],\n",
            "        ...,\n",
            "        [-0.0382,  0.0486, -0.0742,  ..., -0.0481, -0.0111, -0.0347],\n",
            "        [-0.0364,  0.0485, -0.0742,  ..., -0.0442, -0.0083, -0.0350],\n",
            "        [-0.0346,  0.0509, -0.0758,  ..., -0.0458, -0.0014, -0.0341]],\n",
            "       device='cuda:0', grad_fn=<CatBackward>)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mhx\u001b[0m \u001b[0;34m= None\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mbatch_sizes\u001b[0m \u001b[0;34m= None\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mmax_batch_size\u001b[0m \u001b[0;34m= 100\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36msorted_indices\u001b[0m \u001b[0;34m= None\u001b[0m\n",
            "\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self=LSTM(100, 200), input=tensor([[-0.0265,  0.0039, -0.0380,  ..., -0.007...],\n",
            "       device='cuda:0', grad_fn=<CatBackward>), hx=(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "       ...0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "       ...0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')), batch_sizes=None, max_batch_size=100, sorted_indices=None)\u001b[0m\n",
            "\u001b[1;32m    521\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mself.check_forward_args\u001b[0m \u001b[0;34m= <bound method LSTM.check_forward_args of LSTM(100, 200)>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36minput\u001b[0m \u001b[0;34m= tensor([[-0.0265,  0.0039, -0.0380,  ..., -0.0075, -0.0019, -0.0048],\n",
            "        [-0.0377,  0.0153, -0.0527,  ..., -0.0179, -0.0020, -0.0122],\n",
            "        [-0.0400,  0.0250, -0.0616,  ..., -0.0276,  0.0002, -0.0201],\n",
            "        ...,\n",
            "        [-0.0382,  0.0486, -0.0742,  ..., -0.0481, -0.0111, -0.0347],\n",
            "        [-0.0364,  0.0485, -0.0742,  ..., -0.0442, -0.0083, -0.0350],\n",
            "        [-0.0346,  0.0509, -0.0758,  ..., -0.0458, -0.0014, -0.0341]],\n",
            "       device='cuda:0', grad_fn=<CatBackward>)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mhx\u001b[0m \u001b[0;34m= (tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'))\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mbatch_sizes\u001b[0m \u001b[0;34m= None\u001b[0m\n",
            "\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self=LSTM(100, 200), input=tensor([[-0.0265,  0.0039, -0.0380,  ..., -0.007...],\n",
            "       device='cuda:0', grad_fn=<CatBackward>), hidden=(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "       ...0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0'), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "       ...0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0')), batch_sizes=None)\u001b[0m\n",
            "\u001b[1;32m    494\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    495\u001b[0m         \u001b[0;31m# type: (Tensor, Tuple[Tensor, Tensor], Optional[Tensor]) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m        \u001b[0;36mself.check_input\u001b[0m \u001b[0;34m= <bound method RNNBase.check_input of LSTM(100, 200)>\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36minput\u001b[0m \u001b[0;34m= tensor([[-0.0265,  0.0039, -0.0380,  ..., -0.0075, -0.0019, -0.0048],\n",
            "        [-0.0377,  0.0153, -0.0527,  ..., -0.0179, -0.0020, -0.0122],\n",
            "        [-0.0400,  0.0250, -0.0616,  ..., -0.0276,  0.0002, -0.0201],\n",
            "        ...,\n",
            "        [-0.0382,  0.0486, -0.0742,  ..., -0.0481, -0.0111, -0.0347],\n",
            "        [-0.0364,  0.0485, -0.0742,  ..., -0.0442, -0.0083, -0.0350],\n",
            "        [-0.0346,  0.0509, -0.0758,  ..., -0.0458, -0.0014, -0.0341]],\n",
            "       device='cuda:0', grad_fn=<CatBackward>)\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36mbatch_sizes\u001b[0m \u001b[0;34m= None\u001b[0m\n",
            "\u001b[1;32m    497\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self=LSTM(100, 200), input=tensor([[-0.0265,  0.0039, -0.0380,  ..., -0.007...],\n",
            "       device='cuda:0', grad_fn=<CatBackward>), batch_sizes=None)\u001b[0m\n",
            "\u001b[1;32m    143\u001b[0m             raise RuntimeError(\n",
            "\u001b[1;32m    144\u001b[0m                 'input must have {} dimensions, got {}'.format(\n",
            "\u001b[0;32m--> 145\u001b[0;31m                     expected_input_dim, input.dim()))\n",
            "\u001b[0m        \u001b[0;36mexpected_input_dim\u001b[0m \u001b[0;34m= 3\u001b[0m\u001b[0;34m\n",
            "        \u001b[0m\u001b[0;36minput.dim\u001b[0m \u001b[0;34m= <built-in method dim of Tensor object at 0x7f065b98acf0>\u001b[0m\n",
            "\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    147\u001b[0m             raise RuntimeError(\n",
            "\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-8afda017ba41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-8e7b7fe07ce2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epochs)\u001b[0m\n\u001b[1;32m     24\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_manhattan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;31m# type: (Tensor, Tuple[Tensor, Tensor], Optional[Tensor]) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    143\u001b[0m             raise RuntimeError(\n\u001b[1;32m    144\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[0;32m--> 145\u001b[0;31m                     expected_input_dim, input.dim()))\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pcwtP_a9pk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}