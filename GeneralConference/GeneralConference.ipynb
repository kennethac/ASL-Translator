{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GeneralConference.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te3Bjkwhe2Ue",
        "colab_type": "text"
      },
      "source": [
        "This notebook uses data scraped from the churchofjesuschrist.org website with ASL language general conference talks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uPsFv-ccwAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !curl -o gc.zip https://students.cs.byu.edu/~kac1995/2000.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOllGGoO0edW",
        "colab_type": "code",
        "outputId": "071f99eb-811d-4d89-984b-3f47f331c566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\"\"\n",
        "  1. Mount Google Drive (no need to check if already mounted, it does that for you)\n",
        "  2. \n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPYkGq9k0nZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf \"/content/gc\"\n",
        "!unzip \"/content/gdrive/My Drive/CS474 Final Project/GC/2000.zip\" > /dev/null\n",
        "!mv \"/content/users/guest/k/kac1995/dev/CS474-General-Conference-Downloader/gc\" \"/content/gc\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN_UowwLoUzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# root directory has a structure like \"year/month/talk/[video|text]\"\n",
        "root_dir = \"/content/gc\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgRirH6MHIbf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "f74ab2c4-5509-492b-b41f-b30583c78e4b"
      },
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm\n",
        "!sudo apt install libavdevice-dev libavfilter-dev > /dev/null # Required to get av to install\n",
        "!pip3 install av # Required for torchvision to work with videos."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.6/dist-packages (6.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p_UyQQ2HI4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms, utils, datasets\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import gc\n",
        "import os\n",
        "import av\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "assert torch.cuda.is_available(), \"You need to request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNTxSKekHS-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !ls \"/content/gc/2000/04\"\n",
        "test_file = \"/content/gc/2000/04/are-you-still-here/frames.mp4\"\n",
        "vid, audio, meta = torchvision.io.video.read_video(test_file, pts_unit=\"sec\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj-zJMqyH8n1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "147629b6-09af-4f26-ce45-89f89c31767e"
      },
      "source": [
        "!pip3 install av # Required for torchvision to work with videos."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: av in /usr/local/lib/python3.6/dist-packages (6.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO0RMpJBKLAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_minutes = 1\n",
        "fps = 10\n",
        "sample_frames = sample_minutes * 60 * fps\n",
        "\n",
        "class GeneralConferenceDataset(Dataset):\n",
        "  def __init__(self, root=root_dir, video_file=\"frames.mp4\", text_file=\"text.txt\", frames_per_item=sample_frames):\n",
        "    self.root_dir = root\n",
        "    self.video_file = video_file\n",
        "    self.text_file = text_file\n",
        "    self.frames_per_item = frames_per_item\n",
        "    self.years = self._discover_folders(root_dir)\n",
        "    self.months = self._discover_folders(self.years)\n",
        "    self.talks = self._discover_folders(self.months)\n",
        "  \n",
        "  def _discover_folders(self, parent):\n",
        "    if type(parent) != list: # we're gonna flatten lists, so this makes that easier\n",
        "      parent = [parent]\n",
        "    return [os.path.join(p, d.name) for p in parent for d in os.scandir(p) if d.is_dir()]\n",
        "\n",
        "  def _load_text(self, talk_dir):\n",
        "    \"\"\"\n",
        "    Loads the text in the given talk as a list of word2vec tors.\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    \"\"\"\n",
        "      Returns a random sample of the video at index, and the text we hope that it represents.\n",
        "    \"\"\"\n",
        "    # Load the video and get a samle of the frames. Video is of size [num_frames, h, w, c]\n",
        "    video, _, meta = torchvision.io.video.read_video(os.path.join(talk_dir, self.video_file))\n",
        "    num_frames = video.size(0)\n",
        "    length = self.frames_per_item\n",
        "    start_frame = random.randint( 0, num_frames - length )\n",
        "    frame_sample = v[start_frame:start_frame + length]\n",
        "\n",
        "    # Now get a chunk of text of hopefully comparable spot.\n",
        "    percent = length / num_frames\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6HE1Qu6Nrme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = GeneralConferenceDataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sG-gkCENt19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bbb31f6e-9c93-4cff-871a-036e3f6a3a2d"
      },
      "source": [
        "  !ls '/content/gc/2000/10/sanctify-yourselves'"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frames.mp4  text.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dHVbYjdOdz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}