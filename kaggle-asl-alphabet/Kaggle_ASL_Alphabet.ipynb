{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle ASL Alphabet",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDwJO9lsbuTv",
        "colab_type": "text"
      },
      "source": [
        "The data for this notebook comes from https://www.kaggle.com/grassknoted/asl-alphabet/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vhw70_FbDcp",
        "colab_type": "code",
        "outputId": "da45452c-da1e-4091-808d-509846fc7886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\"\"\"\n",
        "  1. Mount Google Drive (no need to check if already mounted, it does that for you)\n",
        "  2. \n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "root_dir = \"/content/gdrive/My Drive/CS474 Final Project/Kaggle ASL Alphabet/\"\n",
        "train_dir = \"asl_alphabet_train/asl_alphabet_train\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak1Cqg7cP-kF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "ad14b317-2192-4ef7-e487-7e119ecd2dee"
      },
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torchvision\n",
        "import os\n",
        "import gzip\n",
        "import tarfile\n",
        "import gc\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "assert torch.cuda.is_available(), \"You need to request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.0+cu100)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.1+cu100)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.3)\n",
            "Requirement already satisfied: torch==1.3.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.3.0+cu100)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c962bfd9f09b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0m__ITB__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoFormattedTB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Verbose'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor_scheme\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LightBg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"You need to request a GPU from Runtime > Change Runtime\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: You need to request a GPU from Runtime > Change Runtime"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8oL6AqMPoAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ASLDataset(Dataset):\n",
        "  def to_one_hot(self, class_index):\n",
        "    oh = torch.zeros((len(self.dataset_folder)))\n",
        "    oh[class_index] = 1\n",
        "    return oh\n",
        "    \n",
        "  def __init__(self, root_path, train_path, size=512):\n",
        "      self.dataset_folder = torchvision.datasets.ImageFolder(os.path.join(root_path, train_path) ,transform = transforms.Compose([transforms.Resize(size),transforms.ToTensor()]))\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    sample = self.dataset_folder[index]\n",
        "    return sample[0], self.to_one_hot(sample[1])\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.dataset_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb5vda7aQSwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = ASLDataset(root_dir, train_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZpQblwUQgTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10\n",
        "validation_split = 0.2\n",
        "shuffle_dataset = True\n",
        "random_seed= 12\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, \n",
        "                                           sampler=train_sampler)\n",
        "validation_loader = DataLoader(dataset, batch_size=batch_size,\n",
        "                                                sampler=valid_sampler)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gNj0-7ePcRF",
        "colab_type": "text"
      },
      "source": [
        "# SSH Access\n",
        "\n",
        "If ssh_connect is True, an ssh server will be set up on the hosting server. Ergo power."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmJosbn3c0i_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ssh_connect = False\n",
        "if ssh_connect:\n",
        "  import random, string, getpass\n",
        "\n",
        "  password = ''.join(random.choice(string.ascii_letters + string.digits) for i in range(20))\n",
        "  alias = ''.join(random.choice(string.ascii_letters + string.digits) for i in range(8))\n",
        "  ! echo root:$password | chpasswd\n",
        "\n",
        "  ! apt-get install -qq -o=Dpkg::Use-Pty=0 openssh-server pwgen > /dev/null\n",
        "  ! mkdir -p /var/run/sshd\n",
        "  ! echo \"PermitRootLogin yes\" >> /etc/ssh/sshd_config && echo \"PasswordAuthentication yes\" >> /etc/ssh/sshd_config\n",
        "  ! echo \"LD_LIBRARY_PATH=/usr/lib64-nvidia\" >> /root/.bashrc && echo \"export LD_LIBRARY_PATH\" >> /root/.bashrc\n",
        "  get_ipython().system_raw('/usr/sbin/sshd -D &')\n",
        "\n",
        "  print('sshpass -p {} ssh -o \"StrictHostKeyChecking no\" -J serveo.net root@{}'.format(password, alias))\n",
        "  ! ssh -o \"StrictHostKeyChecking no\" -R $alias:22:localhost:22 serveo.net"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}