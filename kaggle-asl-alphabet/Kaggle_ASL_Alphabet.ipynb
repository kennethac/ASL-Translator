{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle ASL Alphabet",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDwJO9lsbuTv",
        "colab_type": "text"
      },
      "source": [
        "The data for this notebook comes from https://www.kaggle.com/grassknoted/asl-alphabet/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vhw70_FbDcp",
        "colab_type": "code",
        "outputId": "405e794f-aacf-4dfc-e90f-f0e278b900b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "\"\"\"\n",
        "  1. Mount Google Drive (no need to check if already mounted, it does that for you)\n",
        "  2. \n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "root_dir = \"/content/gdrive/My Drive/CS474 Final Project/Kaggle ASL Alphabet/\"\n",
        "train_dir = \"asl_alphabet_train/asl_alphabet_train\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak1Cqg7cP-kF",
        "colab_type": "code",
        "outputId": "4fe378ef-bd00-461f-f678-a0a1cfa340c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        "import torchvision\n",
        "import os\n",
        "import gzip\n",
        "import tarfile\n",
        "import gc\n",
        "from IPython.core.ultratb import AutoFormattedTB\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "__ITB__ = AutoFormattedTB(mode = 'Verbose',color_scheme='LightBg', tb_offset = 1)\n",
        "\n",
        "assert torch.cuda.is_available(), \"You need to request a GPU from Runtime > Change Runtime\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.0+cu100)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.1+cu100)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: torch==1.3.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.3.0+cu100)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8oL6AqMPoAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ASLDataset(Dataset):\n",
        "  def to_one_hot(self, class_index):\n",
        "    oh = torch.zeros((len(self.dataset_folder.classes)))\n",
        "    oh[class_index] = 1\n",
        "    return oh\n",
        "    \n",
        "  def __init__(self, root_path, train_path, size=512):\n",
        "      self.dataset_folder = torchvision.datasets.ImageFolder(os.path.join(root_path, train_path) ,transform = transforms.Compose([transforms.Resize(size),transforms.ToTensor()]))\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    sample = self.dataset_folder[index]\n",
        "    return sample[0], sample[1]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.dataset_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lnKG34H1gob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNetwork(nn.Module):\n",
        "  def __init__(self, input_channels, output_classes, dimensions = 512):\n",
        "    super(ConvNetwork, self).__init__()\n",
        "    \n",
        "    final_dim = dimensions - 6 - 8 # this calculates the size that the last kernel needs to be. Should be updated according to the conv2ds in the sequence.\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(input_channels, 100, (3, 3), padding=(1,1)),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(100, 100, (5, 5), padding=(2,2)),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(100, 100, (5, 5), padding=(2,2)),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(100, 100, (7, 7), padding=(0,0)),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(100, 10, (9, 9), padding=(0,0)),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(10, output_classes, (final_dim, final_dim), padding=(0,0))\n",
        "\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "      return self.net(x).squeeze(2).squeeze(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb5vda7aQSwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = ASLDataset(root_dir, train_dir, size=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZpQblwUQgTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10\n",
        "validation_split = 0.2\n",
        "shuffle_dataset = True\n",
        "random_seed= 12\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, \n",
        "                                           sampler=train_sampler)\n",
        "validation_loader = DataLoader(dataset, batch_size=batch_size,\n",
        "                                                sampler=valid_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOurZtneWHxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize Model\n",
        "model = ConvNetwork(3, len(dataset.dataset_folder.classes), dimensions=256)\n",
        "model = model.cuda() #use GPU\n",
        "\n",
        "# Initialize Objective and Optimizer and other parameters\n",
        "objective = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKvaGpQVRFfH",
        "colab_type": "code",
        "outputId": "8e146fda-0a66-4066-e123-c2d14a1a467e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# This is what was talked about in the video for memory management\n",
        "num_epochs = 1\n",
        "valid_frequency = 10\n",
        "\n",
        "train_losses = []\n",
        "validation_losses = []\n",
        "\n",
        "def scope():\n",
        "  try:\n",
        "    #your code for calling dataset and dataloader\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    loop = tqdm(\n",
        "        total=(len(train_loader) * num_epochs) +\n",
        "          (len(validation_loader) * (num_epochs // valid_frequency))\n",
        "        , position = 0)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      sum_loss = 0\n",
        "      count_loss = 0\n",
        "\n",
        "      for x, y_truth in train_loader:\n",
        "        x, y_truth = x.cuda(async=True), y_truth.cuda(async=True)\n",
        "        optimizer.zero_grad()\n",
        "        y_hat = model(x)\n",
        "        y_long = y_truth.long()\n",
        "\n",
        "        # print(\"\\n\\n-----------\\ny_hat: {}, y_long: {}\\n-----------\\n\\n\".format(y_hat.size(), y_long.size()))\n",
        "        loss = objective(y_hat, y_long)\n",
        "        sum_loss += loss.item()\n",
        "        count_loss += 1\n",
        "\n",
        "        loop.set_description(\"epoch:{}, loss:{:.4f}\".format(epoch, loss.item()))\n",
        "        loop.update(1)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "      train_losses.append((epoch, sum_loss / count_loss))\n",
        "\n",
        "      if epoch % valid_frequency == 0:\n",
        "        sum_loss = 0\n",
        "        count_loss = 0\n",
        "        with torch.no_grad():\n",
        "          for x, y_truth in valid_loader:\n",
        "            x, y_truth = x.cuda(async=True), y_truth.cuda(async=True)\n",
        "            y_hat = model(x)\n",
        "            loss = objective(y_hat, y_truth.long())\n",
        "            sum_loss += loss.item()\n",
        "            count_loss += 1       \n",
        "          validation_losses.append((epoch, sum_loss / count_loss))\n",
        "            # validation_accuracies.append([total_batch_counter, sum_acc / count])\n",
        "          \n",
        "    # Call your model, figure out loss and accuracy\n",
        "    \n",
        "  except:\n",
        "    __ITB__()\n",
        "    raise\n",
        "    \n",
        "scope()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:0, loss:3.3672:  14%|█▍        | 992/6960 [1:12:10<7:42:58,  4.65s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gNj0-7ePcRF",
        "colab_type": "text"
      },
      "source": [
        "# SSH Access\n",
        "\n",
        "If ssh_connect is True, an ssh server will be set up on the hosting server. Ergo power."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmJosbn3c0i_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ssh_connect = False\n",
        "if ssh_connect:\n",
        "  import random, string, getpass\n",
        "\n",
        "  password = ''.join(random.choice(string.ascii_letters + string.digits) for i in range(20))\n",
        "  alias = ''.join(random.choice(string.ascii_letters + string.digits) for i in range(8))\n",
        "  ! echo root:$password | chpasswd\n",
        "\n",
        "  ! apt-get install -qq -o=Dpkg::Use-Pty=0 openssh-server pwgen > /dev/null\n",
        "  ! mkdir -p /var/run/sshd\n",
        "  ! echo \"PermitRootLogin yes\" >> /etc/ssh/sshd_config && echo \"PasswordAuthentication yes\" >> /etc/ssh/sshd_config\n",
        "  ! echo \"LD_LIBRARY_PATH=/usr/lib64-nvidia\" >> /root/.bashrc && echo \"export LD_LIBRARY_PATH\" >> /root/.bashrc\n",
        "  get_ipython().system_raw('/usr/sbin/sshd -D &')\n",
        "\n",
        "  print('sshpass -p {} ssh -o \"StrictHostKeyChecking no\" -J serveo.net root@{}'.format(password, alias))\n",
        "  ! ssh -o \"StrictHostKeyChecking no\" -R $alias:22:localhost:22 serveo.net"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}